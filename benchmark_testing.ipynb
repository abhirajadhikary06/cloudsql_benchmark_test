{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd42f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "neon_url = os.getenv(\"NEONDB_DATABASE_URL\")\n",
    "render_url = os.getenv(\"RENDER_DATABASE_URL\")\n",
    "xata_url = os.getenv(\"XATA_DATABASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f332333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "import time\n",
    "import statistics\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8984d1b",
   "metadata": {},
   "source": [
    "# Avg Connection Latency of NeonDB: 494.19 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd1d517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Connection Latency of NeonDB: 494.19 ms\n"
     ]
    }
   ],
   "source": [
    "conn_str = os.getenv(\"NEONDB_DATABASE_URL\")\n",
    "latencies = []\n",
    "\n",
    "for _ in range(100):\n",
    "    start = time.perf_counter()\n",
    "    conn = psycopg.connect(conn_str)\n",
    "    conn.close()\n",
    "    end = time.perf_counter()\n",
    "    latencies.append((end - start) * 1000)  # ms\n",
    "\n",
    "avg_latency = statistics.mean(latencies)\n",
    "print(f\"Avg Connection Latency of NeonDB: {avg_latency:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9855ab5d",
   "metadata": {},
   "source": [
    "# Avg Connection Latency of Render: 948.76 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7ad9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Connection Latency of Render: 948.76 ms\n"
     ]
    }
   ],
   "source": [
    "conn_str = os.getenv(\"RENDER_DATABASE_URL\")\n",
    "latencies = []\n",
    "\n",
    "for _ in range(100):\n",
    "    start = time.perf_counter()\n",
    "    conn = psycopg.connect(conn_str)\n",
    "    conn.close()\n",
    "    end = time.perf_counter()\n",
    "    latencies.append((end - start) * 1000)  # ms\n",
    "\n",
    "avg_latency = statistics.mean(latencies)\n",
    "print(f\"Avg Connection Latency of Render: {avg_latency:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a662e",
   "metadata": {},
   "source": [
    "# Avg Connection Latency of Xata: 984.92 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f495d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Connection Latency of Xata: 984.92 ms\n"
     ]
    }
   ],
   "source": [
    "conn_str = os.getenv(\"XATA_DATABASE_URL\")\n",
    "latencies = []\n",
    "\n",
    "for _ in range(100):\n",
    "    start = time.perf_counter()\n",
    "    conn = psycopg.connect(conn_str)\n",
    "    conn.close()\n",
    "    end = time.perf_counter()\n",
    "    latencies.append((end - start) * 1000)  # ms\n",
    "\n",
    "avg_latency = statistics.mean(latencies)\n",
    "print(f\"Avg Connection Latency of Xata: {avg_latency:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6844d392",
   "metadata": {},
   "source": [
    "# NeonDB (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a6e599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed Query (uni_roll) Avg: 85.92 ms (n=100)\n",
      "Non-Indexed Query (name LIKE) Avg: 90.95 ms\n",
      "Branch Filter Avg: 86.97 ms\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Benchmark 2: Query Latency (SELECT) - students table\n",
    "# %%\n",
    "import psycopg\n",
    "import time\n",
    "import statistics\n",
    "import os\n",
    "import random\n",
    "\n",
    "db_url = os.getenv(\"NEONDB_DATABASE_URL\")  # Neon/Render/Xata URL\n",
    "conn = psycopg.connect(db_url)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Warm up connection\n",
    "cur.execute(\"SELECT 1\")\n",
    "conn.commit()\n",
    "\n",
    "# Indexed SELECT on uni_roll (PK, indexed)\n",
    "indexed_latencies = []\n",
    "for _ in range(100):\n",
    "    uni_roll = f\"UNI{random.randint(1, 50000):06d}\"  # Format matching UNI000001 - UNI050000\n",
    "    start = time.perf_counter()\n",
    "    cur.execute(\"SELECT name, branch FROM students WHERE uni_roll = %s\", (uni_roll,))\n",
    "    result = cur.fetchone()\n",
    "    end = time.perf_counter()\n",
    "    if result:  # Only count successful hits\n",
    "        indexed_latencies.append((end - start) * 1000)\n",
    "\n",
    "# Non-indexed SELECT on name (partial match, full scan)\n",
    "non_indexed_latencies = []\n",
    "for _ in range(100):\n",
    "    name_pattern = f\"%{random.choice(['Andrea', 'Vicki', 'Steven', 'Christopher', 'Tyrone', 'Linda', 'Vanessa', 'Megan', 'Paige', 'James', 'Nicholas', 'Thomas', 'Tracy'])}%\"\n",
    "    start = time.perf_counter()\n",
    "    cur.execute(\"SELECT uni_roll, branch FROM students WHERE name LIKE %s\", (name_pattern,))\n",
    "    results = cur.fetchall()\n",
    "    end = time.perf_counter()\n",
    "    non_indexed_latencies.append((end - start) * 1000)\n",
    "\n",
    "# Branch filter (non-indexed, selective)\n",
    "branch_latencies = []\n",
    "branches = [\"EE\", \"CHE\", \"ECE\", \"ME\", \"CSE\", \"CE\", \"PHM\", \"BT\"]\n",
    "for _ in range(100):\n",
    "    branch = random.choice(branches)\n",
    "    start = time.perf_counter()\n",
    "    cur.execute(\"SELECT count(*) FROM students WHERE branch = %s\", (branch,))\n",
    "    cur.fetchone()\n",
    "    end = time.perf_counter()\n",
    "    branch_latencies.append((end - start) * 1000)\n",
    "\n",
    "print(f\"Indexed Query (uni_roll) Avg: {statistics.mean(indexed_latencies):.2f} ms (n={len(indexed_latencies)})\")\n",
    "print(f\"Non-Indexed Query (name LIKE) Avg: {statistics.mean(non_indexed_latencies):.2f} ms\")\n",
    "print(f\"Branch Filter Avg: {statistics.mean(branch_latencies):.2f} ms\")\n",
    "\n",
    "# Store results\n",
    "query_results = {\n",
    "    'indexed_avg_ms': statistics.mean(indexed_latencies) if indexed_latencies else 0,\n",
    "    'non_indexed_avg_ms': statistics.mean(non_indexed_latencies),\n",
    "    'branch_avg_ms': statistics.mean(branch_latencies)\n",
    "}\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2165e",
   "metadata": {},
   "source": [
    "# Xata (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22d0705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed Query (uni_roll) Avg: 162.58 ms (n=100)\n",
      "Non-Indexed Query (name LIKE) Avg: 177.77 ms\n",
      "Branch Filter Avg: 170.61 ms\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Benchmark 2: Query Latency (SELECT) - students table\n",
    "# %%\n",
    "import psycopg\n",
    "import time\n",
    "import statistics\n",
    "import os\n",
    "import random\n",
    "\n",
    "db_url = os.getenv(\"XATA_DATABASE_URL\")  # Neon/Render/Xata URL\n",
    "conn = psycopg.connect(db_url)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Warm up connection\n",
    "cur.execute(\"SELECT 1\")\n",
    "conn.commit()\n",
    "\n",
    "# Indexed SELECT on uni_roll (PK, indexed)\n",
    "indexed_latencies = []\n",
    "for _ in range(100):\n",
    "    uni_roll = f\"UNI{random.randint(1, 50000):06d}\"  # Format matching UNI000001 - UNI050000\n",
    "    start = time.perf_counter()\n",
    "    cur.execute(\"SELECT name, branch FROM students WHERE uni_roll = %s\", (uni_roll,))\n",
    "    result = cur.fetchone()\n",
    "    end = time.perf_counter()\n",
    "    if result:  # Only count successful hits\n",
    "        indexed_latencies.append((end - start) * 1000)\n",
    "\n",
    "# Non-indexed SELECT on name (partial match, full scan)\n",
    "non_indexed_latencies = []\n",
    "for _ in range(100):\n",
    "    name_pattern = f\"%{random.choice(['Andrea', 'Vicki', 'Steven', 'Christopher', 'Tyrone', 'Linda', 'Vanessa', 'Megan', 'Paige', 'James', 'Nicholas', 'Thomas', 'Tracy'])}%\"\n",
    "    start = time.perf_counter()\n",
    "    cur.execute(\"SELECT uni_roll, branch FROM students WHERE name LIKE %s\", (name_pattern,))\n",
    "    results = cur.fetchall()\n",
    "    end = time.perf_counter()\n",
    "    non_indexed_latencies.append((end - start) * 1000)\n",
    "\n",
    "# Branch filter (non-indexed, selective)\n",
    "branch_latencies = []\n",
    "branches = [\"EE\", \"CHE\", \"ECE\", \"ME\", \"CSE\", \"CE\", \"PHM\", \"BT\"]\n",
    "for _ in range(100):\n",
    "    branch = random.choice(branches)\n",
    "    start = time.perf_counter()\n",
    "    cur.execute(\"SELECT count(*) FROM students WHERE branch = %s\", (branch,))\n",
    "    cur.fetchone()\n",
    "    end = time.perf_counter()\n",
    "    branch_latencies.append((end - start) * 1000)\n",
    "\n",
    "print(f\"Indexed Query (uni_roll) Avg: {statistics.mean(indexed_latencies):.2f} ms (n={len(indexed_latencies)})\")\n",
    "print(f\"Non-Indexed Query (name LIKE) Avg: {statistics.mean(non_indexed_latencies):.2f} ms\")\n",
    "print(f\"Branch Filter Avg: {statistics.mean(branch_latencies):.2f} ms\")\n",
    "\n",
    "# Store results\n",
    "query_results = {\n",
    "    'indexed_avg_ms': statistics.mean(indexed_latencies) if indexed_latencies else 0,\n",
    "    'non_indexed_avg_ms': statistics.mean(non_indexed_latencies),\n",
    "    'branch_avg_ms': statistics.mean(branch_latencies)\n",
    "}\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e98ef",
   "metadata": {},
   "source": [
    "# Render (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6e0f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed Query (uni_roll) Avg: 76.06 ms (n=100)\n",
      "Non-Indexed Query (name LIKE) Avg: 106.81 ms\n",
      "Branch Filter Avg: 92.22 ms\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Benchmark 2: Query Latency (SELECT) - students table\n",
    "# %%\n",
    "import psycopg\n",
    "import time\n",
    "import statistics\n",
    "import os\n",
    "import random\n",
    "\n",
    "db_url = os.getenv(\"RENDER_DATABASE_URL\")  # Neon/Render/Xata URL\n",
    "conn = psycopg.connect(db_url)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Warm up connection\n",
    "cur.execute(\"SELECT 1\")\n",
    "conn.commit()\n",
    "\n",
    "# Indexed SELECT on uni_roll (PK, indexed)\n",
    "indexed_latencies = []\n",
    "for _ in range(100):\n",
    "    uni_roll = f\"UNI{random.randint(1, 50000):06d}\"  # Format matching UNI000001 - UNI050000\n",
    "    start = time.perf_counter()\n",
    "    cur.execute(\"SELECT name, branch FROM students WHERE uni_roll = %s\", (uni_roll,))\n",
    "    result = cur.fetchone()\n",
    "    end = time.perf_counter()\n",
    "    if result:  # Only count successful hits\n",
    "        indexed_latencies.append((end - start) * 1000)\n",
    "\n",
    "# Non-indexed SELECT on name (partial match, full scan)\n",
    "non_indexed_latencies = []\n",
    "for _ in range(100):\n",
    "    name_pattern = f\"%{random.choice(['Andrea', 'Vicki', 'Steven', 'Christopher', 'Tyrone', 'Linda', 'Vanessa', 'Megan', 'Paige', 'James', 'Nicholas', 'Thomas', 'Tracy'])}%\"\n",
    "    start = time.perf_counter()\n",
    "    cur.execute(\"SELECT uni_roll, branch FROM students WHERE name LIKE %s\", (name_pattern,))\n",
    "    results = cur.fetchall()\n",
    "    end = time.perf_counter()\n",
    "    non_indexed_latencies.append((end - start) * 1000)\n",
    "\n",
    "# Branch filter (non-indexed, selective)\n",
    "branch_latencies = []\n",
    "branches = [\"EE\", \"CHE\", \"ECE\", \"ME\", \"CSE\", \"CE\", \"PHM\", \"BT\"]\n",
    "for _ in range(100):\n",
    "    branch = random.choice(branches)\n",
    "    start = time.perf_counter()\n",
    "    cur.execute(\"SELECT count(*) FROM students WHERE branch = %s\", (branch,))\n",
    "    cur.fetchone()\n",
    "    end = time.perf_counter()\n",
    "    branch_latencies.append((end - start) * 1000)\n",
    "\n",
    "print(f\"Indexed Query (uni_roll) Avg: {statistics.mean(indexed_latencies):.2f} ms (n={len(indexed_latencies)})\")\n",
    "print(f\"Non-Indexed Query (name LIKE) Avg: {statistics.mean(non_indexed_latencies):.2f} ms\")\n",
    "print(f\"Branch Filter Avg: {statistics.mean(branch_latencies):.2f} ms\")\n",
    "\n",
    "# Store results\n",
    "query_results = {\n",
    "    'indexed_avg_ms': statistics.mean(indexed_latencies) if indexed_latencies else 0,\n",
    "    'non_indexed_avg_ms': statistics.mean(non_indexed_latencies),\n",
    "    'branch_avg_ms': statistics.mean(branch_latencies)\n",
    "}\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5529389",
   "metadata": {},
   "source": [
    "# Neon (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cc95cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT Throughput: 1530 rows/sec\n",
      "UPDATE Throughput: 343 rows/sec\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Benchmark 3: Write Throughput (INSERT/UPDATE) - students table\n",
    "# %%\n",
    "import psycopg\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "branches = [\"EE\", \"CHE\", \"ECE\", \"ME\", \"CSE\", \"CE\", \"PHM\", \"BT\"]\n",
    "\n",
    "db_url = os.getenv(\"NEONDB_DATABASE_URL\")\n",
    "conn = psycopg.connect(db_url)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Bulk INSERT 1K new students\n",
    "start = time.perf_counter()\n",
    "insert_data = []\n",
    "for i in range(1000):\n",
    "    roll = f\"TEMP{random.randint(100000, 999999):06d}\"  # Temporary rolls to avoid conflicts, matching 6-digit format\n",
    "    name = fake.name() + random.choice([\"\", \" DVM\", \" PhD\", \" MD\"])  # Optional titles like in sample\n",
    "    insert_data.append((name, roll, random.choice(branches)))\n",
    "\n",
    "cur.executemany(\"\"\"\n",
    "    INSERT INTO students (name, uni_roll, branch) \n",
    "    VALUES (%s, %s, %s)\n",
    "    ON CONFLICT (uni_roll) DO NOTHING\n",
    "\"\"\", insert_data)\n",
    "conn.commit()\n",
    "insert_time = time.perf_counter() - start\n",
    "insert_tps = 1000 / insert_time if insert_time > 0 else 0\n",
    "\n",
    "# Bulk UPDATE 1K existing students\n",
    "existing_rolls = [f\"UNI{random.randint(1, 50000):06d}\" for _ in range(1000)]\n",
    "\n",
    "start = time.perf_counter()\n",
    "for i in range(0, 1000, 100):\n",
    "    batch = existing_rolls[i:i+100]\n",
    "    updates = [(random.choice(branches), roll) for roll in batch]\n",
    "    cur.executemany(\"UPDATE students SET branch = %s WHERE uni_roll = %s\", updates)\n",
    "    conn.commit()\n",
    "update_time = time.perf_counter() - start\n",
    "update_tps = 1000 / update_time if update_time > 0 else 0\n",
    "\n",
    "# Cleanup temp inserts\n",
    "cur.execute(\"DELETE FROM students WHERE uni_roll LIKE 'TEMP%'\")\n",
    "conn.commit()\n",
    "\n",
    "print(f\"INSERT Throughput: {insert_tps:.0f} rows/sec\")\n",
    "print(f\"UPDATE Throughput: {update_tps:.0f} rows/sec\")\n",
    "\n",
    "write_results = {\n",
    "    'insert_tps': insert_tps,\n",
    "    'update_tps': update_tps\n",
    "}\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268521b",
   "metadata": {},
   "source": [
    "# Xata (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\cloudsql_benchmark_test\\venv\\Lib\\site-packages\\psycopg\\connection.py:453\u001b[39m, in \u001b[36mConnection.wait\u001b[39m\u001b[34m(self, gen, interval)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwaiting\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpgconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43msocket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _INTERRUPTED:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\cloudsql_benchmark_test\\venv\\Lib\\site-packages\\psycopg\\waiting.py:239\u001b[39m, in \u001b[36mwait_select\u001b[39m\u001b[34m(gen, fileno, interval)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     rl, wl, xl = select.select(\n\u001b[32m    240\u001b[39m         fnlist \u001b[38;5;28;01mif\u001b[39;00m s & WAIT_R \u001b[38;5;28;01melse\u001b[39;00m empty,\n\u001b[32m    241\u001b[39m         fnlist \u001b[38;5;28;01mif\u001b[39;00m s & WAIT_W \u001b[38;5;28;01melse\u001b[39;00m empty,\n\u001b[32m    242\u001b[39m         fnlist,\n\u001b[32m    243\u001b[39m         interval,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m    245\u001b[39m     ready = \u001b[32m0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     23\u001b[39m     insert_data.append((name, roll, random.choice(branches)))\n\u001b[32m     25\u001b[39m cur.executemany(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m    INSERT INTO students (name, uni_roll, branch) \u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m    VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[33m    ON CONFLICT (uni_roll) DO NOTHING\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m\"\"\"\u001b[39m, insert_data)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m insert_time = time.perf_counter() - start\n\u001b[32m     32\u001b[39m insert_tps = \u001b[32m1000\u001b[39m / insert_time \u001b[38;5;28;01mif\u001b[39;00m insert_time > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\cloudsql_benchmark_test\\venv\\Lib\\site-packages\\psycopg\\connection.py:274\u001b[39m, in \u001b[36mConnection.commit\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Commit any pending transaction to the database.\"\"\"\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lock:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_commit_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\cloudsql_benchmark_test\\venv\\Lib\\site-packages\\psycopg\\connection.py:460\u001b[39m, in \u001b[36mConnection.wait\u001b[39m\u001b[34m(self, gen, interval)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28mself\u001b[39m._try_cancel(timeout=\u001b[32m5.0\u001b[39m)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[43mwaiting\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpgconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43msocket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m e.QueryCanceled:\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# as expected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\cloudsql_benchmark_test\\venv\\Lib\\site-packages\\psycopg\\waiting.py:239\u001b[39m, in \u001b[36mwait_select\u001b[39m\u001b[34m(gen, fileno, interval)\u001b[39m\n\u001b[32m    237\u001b[39m fnlist = (fileno,)\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     rl, wl, xl = select.select(\n\u001b[32m    240\u001b[39m         fnlist \u001b[38;5;28;01mif\u001b[39;00m s & WAIT_R \u001b[38;5;28;01melse\u001b[39;00m empty,\n\u001b[32m    241\u001b[39m         fnlist \u001b[38;5;28;01mif\u001b[39;00m s & WAIT_W \u001b[38;5;28;01melse\u001b[39;00m empty,\n\u001b[32m    242\u001b[39m         fnlist,\n\u001b[32m    243\u001b[39m         interval,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m    245\u001b[39m     ready = \u001b[32m0\u001b[39m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m rl:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Benchmark 3: Write Throughput (INSERT/UPDATE) - students table\n",
    "# %%\n",
    "import psycopg\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "branches = [\"EE\", \"CHE\", \"ECE\", \"ME\", \"CSE\", \"CE\", \"PHM\", \"BT\"]\n",
    "\n",
    "db_url = os.getenv(\"XATA_DATABASE_URL\")\n",
    "conn = psycopg.connect(db_url)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Bulk INSERT 1K new students\n",
    "start = time.perf_counter()\n",
    "insert_data = []\n",
    "for i in range(1000):\n",
    "    roll = f\"TEMP{random.randint(100000, 999999):06d}\"  # Temporary rolls to avoid conflicts, matching 6-digit format\n",
    "    name = fake.name() + random.choice([\"\", \" DVM\", \" PhD\", \" MD\"])  # Optional titles like in sample\n",
    "    insert_data.append((name, roll, random.choice(branches)))\n",
    "\n",
    "cur.executemany(\"\"\"\n",
    "    INSERT INTO students (name, uni_roll, branch) \n",
    "    VALUES (%s, %s, %s)\n",
    "    ON CONFLICT (uni_roll) DO NOTHING\n",
    "\"\"\", insert_data)\n",
    "conn.commit()\n",
    "insert_time = time.perf_counter() - start\n",
    "insert_tps = 1000 / insert_time if insert_time > 0 else 0\n",
    "\n",
    "# Bulk UPDATE 1K existing students\n",
    "existing_rolls = [f\"UNI{random.randint(1, 50000):06d}\" for _ in range(1000)]\n",
    "\n",
    "start = time.perf_counter()\n",
    "for i in range(0, 1000, 100):\n",
    "    batch = existing_rolls[i:i+100]\n",
    "    updates = [(random.choice(branches), roll) for roll in batch]\n",
    "    cur.executemany(\"UPDATE students SET branch = %s WHERE uni_roll = %s\", updates)\n",
    "    conn.commit()\n",
    "update_time = time.perf_counter() - start\n",
    "update_tps = 1000 / update_time if update_time > 0 else 0\n",
    "\n",
    "# Cleanup temp inserts\n",
    "cur.execute(\"DELETE FROM students WHERE uni_roll LIKE 'TEMP%'\")\n",
    "conn.commit()\n",
    "\n",
    "print(f\"INSERT Throughput: {insert_tps:.0f} rows/sec\")\n",
    "print(f\"UPDATE Throughput: {update_tps:.0f} rows/sec\")\n",
    "\n",
    "write_results = {\n",
    "    'insert_tps': insert_tps,\n",
    "    'update_tps': update_tps\n",
    "}\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e801b5",
   "metadata": {},
   "source": [
    "# Render (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53df098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT Throughput: 1842 rows/sec\n",
      "UPDATE Throughput: 470 rows/sec\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Benchmark 3: Write Throughput (INSERT/UPDATE) - students table\n",
    "# %%\n",
    "import psycopg\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "branches = [\"EE\", \"CHE\", \"ECE\", \"ME\", \"CSE\", \"CE\", \"PHM\", \"BT\"]\n",
    "\n",
    "db_url = os.getenv(\"RENDER_DATABASE_URL\")\n",
    "conn = psycopg.connect(db_url)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Bulk INSERT 1K new students\n",
    "start = time.perf_counter()\n",
    "insert_data = []\n",
    "for i in range(1000):\n",
    "    roll = f\"TEMP{random.randint(100000, 999999):06d}\"  # Temporary rolls to avoid conflicts, matching 6-digit format\n",
    "    name = fake.name() + random.choice([\"\", \" DVM\", \" PhD\", \" MD\"])  # Optional titles like in sample\n",
    "    insert_data.append((name, roll, random.choice(branches)))\n",
    "\n",
    "cur.executemany(\"\"\"\n",
    "    INSERT INTO students (name, uni_roll, branch) \n",
    "    VALUES (%s, %s, %s)\n",
    "    ON CONFLICT (uni_roll) DO NOTHING\n",
    "\"\"\", insert_data)\n",
    "conn.commit()\n",
    "insert_time = time.perf_counter() - start\n",
    "insert_tps = 1000 / insert_time if insert_time > 0 else 0\n",
    "\n",
    "# Bulk UPDATE 1K existing students\n",
    "existing_rolls = [f\"UNI{random.randint(1, 50000):06d}\" for _ in range(1000)]\n",
    "\n",
    "start = time.perf_counter()\n",
    "for i in range(0, 1000, 100):\n",
    "    batch = existing_rolls[i:i+100]\n",
    "    updates = [(random.choice(branches), roll) for roll in batch]\n",
    "    cur.executemany(\"UPDATE students SET branch = %s WHERE uni_roll = %s\", updates)\n",
    "    conn.commit()\n",
    "update_time = time.perf_counter() - start\n",
    "update_tps = 1000 / update_time if update_time > 0 else 0\n",
    "\n",
    "# Cleanup temp inserts\n",
    "cur.execute(\"DELETE FROM students WHERE uni_roll LIKE 'TEMP%'\")\n",
    "conn.commit()\n",
    "\n",
    "print(f\"INSERT Throughput: {insert_tps:.0f} rows/sec\")\n",
    "print(f\"UPDATE Throughput: {update_tps:.0f} rows/sec\")\n",
    "\n",
    "write_results = {\n",
    "    'insert_tps': insert_tps,\n",
    "    'update_tps': update_tps\n",
    "}\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2eb76",
   "metadata": {},
   "source": [
    "# Neon (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51d46e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running concurrency tests...\n",
      "Testing 5 concurrent clients...\n",
      "Testing 20 concurrent clients...\n",
      "Testing 50 concurrent clients...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'statistics' has no attribute 'percentile'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_clients \u001b[38;5;129;01min\u001b[39;00m concurrency_levels:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_clients\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m concurrent clients...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m run_concurrency(n_clients)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m     76\u001b[39m         concurrency_results[n_clients] = result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mrun_concurrency\u001b[39m\u001b[34m(num_clients, num_queries)\u001b[39m\n\u001b[32m     56\u001b[39m         all_latencies.extend(result)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_latencies:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     60\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mavg_latency_ms\u001b[39m\u001b[33m'\u001b[39m: statistics.mean(all_latencies),\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mp95_latency_ms\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mstatistics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpercentile\u001b[49m(all_latencies, \u001b[32m95\u001b[39m),\n\u001b[32m     62\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtotal_queries\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(all_latencies),\n\u001b[32m     63\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mclients\u001b[39m\u001b[33m'\u001b[39m: num_clients\n\u001b[32m     64\u001b[39m     }\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'statistics' has no attribute 'percentile'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Benchmark 4: Concurrency Scaling - students table\n",
    "# %%\n",
    "import asyncio\n",
    "import asyncpg\n",
    "import statistics\n",
    "import os\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "branches = [\"EE\", \"CHE\", \"ECE\", \"ME\", \"CSE\", \"CE\", \"PHM\", \"BT\"]\n",
    "\n",
    "async def client_task(conn_str, client_id, num_queries=100):\n",
    "    conn = await asyncpg.connect(conn_str)\n",
    "    query_latencies = []\n",
    "    \n",
    "    for i in range(num_queries):\n",
    "        start = asyncio.get_event_loop().time()\n",
    "        \n",
    "        if random.random() < 0.7:  # 70% SELECT\n",
    "            uni_roll = f\"UNI{random.randint(1, 50000):06d}\"\n",
    "            try:\n",
    "                result = await conn.fetchval(\n",
    "                    \"SELECT name FROM students WHERE uni_roll = $1\", uni_roll\n",
    "                )\n",
    "                if result:\n",
    "                    query_latencies.append((asyncio.get_event_loop().time() - start) * 1000)\n",
    "            except:\n",
    "                pass\n",
    "        else:  # 30% INSERT\n",
    "            temp_roll = f\"TEMP{client_id}_{i:06d}\"\n",
    "            name = fake.name() + random.choice([\"\", \" DVM\", \" PhD\"])\n",
    "            try:\n",
    "                await conn.execute(\n",
    "                    \"INSERT INTO students (name, uni_roll, branch) VALUES ($1, $2, $3) ON CONFLICT DO NOTHING\",\n",
    "                    name, temp_roll, random.choice(branches)\n",
    "                )\n",
    "                query_latencies.append((asyncio.get_event_loop().time() - start) * 1000)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        await asyncio.sleep(0.001)\n",
    "    \n",
    "    await conn.close()\n",
    "    return query_latencies\n",
    "\n",
    "async def run_concurrency(num_clients, num_queries=100):\n",
    "    conn_str = os.getenv(\"NEONDB_DATABASE_URL\")\n",
    "    tasks = [client_task(conn_str, i, num_queries) for i in range(num_clients)]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    \n",
    "    all_latencies = []\n",
    "    for result in results:\n",
    "        if isinstance(result, list):\n",
    "            all_latencies.extend(result)\n",
    "    \n",
    "    if all_latencies:\n",
    "        return {\n",
    "            'avg_latency_ms': statistics.mean(all_latencies),\n",
    "            'p95_latency_ms': statistics.percentile(all_latencies, 95),\n",
    "            'total_queries': len(all_latencies),\n",
    "            'clients': num_clients\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Run tests\n",
    "concurrency_levels = [5, 20, 50]\n",
    "concurrency_results = {}\n",
    "\n",
    "print(\"Running concurrency tests...\")\n",
    "for n_clients in concurrency_levels:\n",
    "    print(f\"Testing {n_clients} concurrent clients...\")\n",
    "    result = await run_concurrency(n_clients)\n",
    "    if result:\n",
    "        concurrency_results[n_clients] = result\n",
    "        print(f\"  {n_clients} clients: {result['avg_latency_ms']:.2f}ms avg, \"\n",
    "              f\"{result['p95_latency_ms']:.2f}ms P95, {result['total_queries']} queries\")\n",
    "    await asyncio.sleep(2)\n",
    "\n",
    "# Cleanup\n",
    "conn = await asyncpg.connect(os.getenv(\"DATABASE_URL\"))\n",
    "await conn.execute(\"DELETE FROM students WHERE uni_roll LIKE 'TEMP%'\")\n",
    "await conn.close()\n",
    "\n",
    "print(\"\\nConcurrency Results:\", concurrency_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c823e",
   "metadata": {},
   "source": [
    "# Neon (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "588b7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running warm query...\n",
      "Warm query: 131.36 ms, Success: True\n",
      "Idling for 15 minutes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Idle\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIdling for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midle_duration//\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43midle_duration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Cold query\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning cold query...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Benchmark 5: Cold Start / Idle Resume Latency - students table\n",
    "# %%\n",
    "import psycopg\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "db_url = os.getenv(\"NEONDB_DATABASE_URL\")\n",
    "idle_duration = 900  # 15 minutes\n",
    "\n",
    "def measure_query_latency(conn_str, query_type=\"warm\"):\n",
    "    conn = psycopg.connect(conn_str, connect_timeout=30)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    if query_type == \"warm\":\n",
    "        uni_roll = f\"UNI{random.randint(1, 15):06d}\"  # Sample from small range for warm\n",
    "        cur.execute(\"SELECT name FROM students WHERE uni_roll = %s LIMIT 1\", (uni_roll,))\n",
    "    else:\n",
    "        branch = random.choice([\"EE\", \"CHE\", \"ECE\"])\n",
    "        cur.execute(\"SELECT count(*) FROM students WHERE branch = %s\", (branch,))\n",
    "    result = cur.fetchone()\n",
    "    end = time.perf_counter()\n",
    "    \n",
    "    latency_ms = (end - start) * 1000\n",
    "    conn.close()\n",
    "    return latency_ms, bool(result)\n",
    "\n",
    "# Warm query\n",
    "print(\"Running warm query...\")\n",
    "warm_latency, warm_success = measure_query_latency(db_url, \"warm\")\n",
    "print(f\"Warm query: {warm_latency:.2f} ms, Success: {warm_success}\")\n",
    "\n",
    "# Idle\n",
    "print(f\"Idling for {idle_duration//60} minutes...\")\n",
    "time.sleep(idle_duration)\n",
    "\n",
    "# Cold query\n",
    "print(\"Running cold query...\")\n",
    "cold_latency, cold_success = measure_query_latency(db_url, \"cold\")\n",
    "print(f\"Cold query: {cold_latency:.2f} ms, Success: {cold_success}\")\n",
    "\n",
    "# Connection latencies (5 iterations for avg)\n",
    "conn_latencies = []\n",
    "for _ in range(5):\n",
    "    start = time.perf_counter()\n",
    "    try:\n",
    "        conn = psycopg.connect(db_url, connect_timeout=30)\n",
    "        conn.close()\n",
    "        conn_latencies.append((time.perf_counter() - start) * 1000)\n",
    "    except Exception as e:\n",
    "        print(f\"Connection failed: {e}\")\n",
    "\n",
    "cold_start_results = {\n",
    "    'warm_query_ms': warm_latency,\n",
    "    'cold_query_ms': cold_latency,\n",
    "    'cold_delta_ms': cold_latency - warm_latency,\n",
    "    'avg_conn_latency_ms': statistics.mean(conn_latencies) if conn_latencies else 0,\n",
    "    'cold_start_factor': (cold_latency / warm_latency) if warm_latency > 0 else 0\n",
    "}\n",
    "\n",
    "print(f\"\\nCold Start Analysis:\")\n",
    "print(f\"Query degradation: {cold_start_results['cold_delta_ms']:.2f} ms\")\n",
    "print(f\"Connection latency: {cold_start_results['avg_conn_latency_ms']:.2f} ms\")\n",
    "print(f\"Performance factor: {cold_start_results['cold_start_factor']:.2f}x slower\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
